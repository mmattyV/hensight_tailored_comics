{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'comic_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomic_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComicDataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'comic_dataset'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "import requests\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TOTAL_POSTS = 7400200 # Total number of posts on Danbooru\n",
    "IMG_PER_BATCH = 200 # Read limit from Danbooru\n",
    "TAGS = ['action', 'looking_at_another', 'romance', 'sad', 'crying', 'angry', 'scared', 'surprised', 'fighting', 'chase', 'talking', 'couple'] # Tags for our categories\n",
    "#STOP_ID = 7400200\n",
    "NUM_TAGS = len(TAGS)\n",
    "## TEMP ##\n",
    "TOTAL_POSTS = 3727400\n",
    "JSON_FILE = 'comic_labels.json'\n",
    "TRAIN_JSON = 'comic_labels_train.json'\n",
    "VAL_JSON = 'comic_labels_val.json'\n",
    "GPU_MODE = 0\n",
    "MPS_MODE = 1\n",
    "CUDA_DEVICE = 0\n",
    "NUM_EPOCHS = 5\n",
    "BASE_LR = 0.001\n",
    "DECAY_WEIGHT = 0.1 \n",
    "EPOCH_DECAY = 30 \n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates directory\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# Returns the tags from TAGS that are in the tag_string of a post; returns False if none of our TAGS are in tag_string\n",
    "def check_tags_in_tag_string(tag_string, tags):\n",
    "    tag_list = []\n",
    "    for tag in tags:\n",
    "        if tag in tag_string:\n",
    "            tag_list.append(tag)\n",
    "    if len(tag_list) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return tag_list\n",
    "    \n",
    "# Copied from custom_hymenoptera_dataset.py\n",
    "# Checks for valid image files (size and extension)\n",
    "def is_valid_image_file(filename, max_pixels=178956970):\n",
    "    # Check file name extension\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff']\n",
    "    if os.path.splitext(filename)[1].lower() not in valid_extensions:\n",
    "        print(f\"Invalid image file extension \\\"{filename}\\\". Skipping this file...\")\n",
    "        return False\n",
    "    \n",
    "    # Temporarily disable the decompression bomb check\n",
    "    original_max_image_pixels = Image.MAX_IMAGE_PIXELS\n",
    "    Image.MAX_IMAGE_PIXELS = None\n",
    "    \n",
    "    # Verify that image file is intact and check its size\n",
    "    try:\n",
    "        with Image.open(filename) as img:\n",
    "            img.verify()  # Verify if it's an image\n",
    "            # Restore the original MAX_IMAGE_PIXELS limit\n",
    "            Image.MAX_IMAGE_PIXELS = original_max_image_pixels\n",
    "            \n",
    "            # Check image size without loading the image into memory\n",
    "            if img.size[0] * img.size[1] > max_pixels:\n",
    "                print(f\"Image {filename} is too large. Skipping this file...\")\n",
    "                return False\n",
    "            return True\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f\"Invalid image file {filename}: {e}\")\n",
    "        # Ensure the MAX_IMAGE_PIXELS limit is restored even if an exception occurs\n",
    "        Image.MAX_IMAGE_PIXELS = original_max_image_pixels\n",
    "        return False\n",
    "    # Ensure the MAX_IMAGE_PIXELS limit is restored in case of any other unexpected exit\n",
    "    Image.MAX_IMAGE_PIXELS = original_max_image_pixels\n",
    "    \n",
    "# Create dir for our comic images\n",
    "images_dir = '../comic_images'\n",
    "create_dir(images_dir)\n",
    "\n",
    "# Dict for image file name and list of tags\n",
    "image_label_dict = {}\n",
    "\n",
    "B = IMG_PER_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3727400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5000/3727400 [00:11<2:25:41, 425.82it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=TOTAL_POSTS)\n",
    "\n",
    "# Loops over all post id's to download images from posts that are tagged \"comic\" and contain at least one of our TAGS\n",
    "# Also creates dict of image file name and associated tags\n",
    "while B <= TOTAL_POSTS:\n",
    "    url = f'https://danbooru.donmai.us/posts.json?page=b{B}&page=a{B-IMG_PER_BATCH}&limit={IMG_PER_BATCH}'\n",
    "    response_pages = requests.get(url)\n",
    "\n",
    "    response_pages_json = response_pages.json()\n",
    "\n",
    "    for page in response_pages_json:\n",
    "        if 'file_url' in page and 'tag_string' in page:\n",
    "            tag_string = page['tag_string']\n",
    "            id = page['id']\n",
    "\n",
    "            scene_tags = check_tags_in_tag_string(tag_string, TAGS)\n",
    "            if 'comic' in page['tag_string'] and scene_tags:\n",
    "                file_url = page['file_url']\n",
    "\n",
    "                image_path = f'{id}.jpg'\n",
    "        \n",
    "                if not os.path.exists(os.path.join(images_dir, image_path)):\n",
    "                    response_img = requests.get(file_url)\n",
    "\n",
    "                    # If post contains relevant tags and has valid image file, save the image with id as name\n",
    "                    if response_img.status_code == 200:\n",
    "                        \n",
    "                        with open(os.path.join(images_dir, image_path), 'wb') as file:\n",
    "                            file.write(response_img.content)\n",
    "                        \n",
    "                # Write values to dict\n",
    "                image_label_dict[image_path] = scene_tags\n",
    "\n",
    "    B += IMG_PER_BATCH\n",
    "    progress_bar.update(200)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "print(image_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dict to .json file\n",
    "with open(JSON_FILE, 'w') as f: \n",
    "     json.dump(image_label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Break data into train and val .json files\n",
    "with open(JSON_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "    total_items = len(data)\n",
    "    val_part_size = int(0.2*total_items)\n",
    "    train_part_size = total_items-val_part_size\n",
    "\n",
    "    keys = list(data.keys())\n",
    "\n",
    "    random.shuffle(keys)\n",
    "\n",
    "    val_part_keys = keys[:val_part_size]\n",
    "    train_part_keys = keys[val_part_size:]\n",
    "\n",
    "    val_part_dict = {key: data[key] for key in val_part_keys}\n",
    "    train_part_dict = {key: data[key] for key in train_part_keys}\n",
    "\n",
    "    with open(TRAIN_JSON, 'w') as t:\n",
    "        json.dump(train_part_dict, t)\n",
    "\n",
    "    with open(VAL_JSON, 'w') as w:\n",
    "        json.dump(val_part_dict, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComicDataset(Dataset):\n",
    "    # Hot encode our labels for our targets\n",
    "    def hot_encode_target(self, tags):\n",
    "        target = torch.zeros(NUM_TAGS)\n",
    "        for tag in tags:\n",
    "            target[TAGS.index(tag)] = 1\n",
    "\n",
    "        return target\n",
    "\n",
    "    def __init__(self, images_dir, json_file, transform=None, target_transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        image_label_dict = {}\n",
    "        class_counts = {}\n",
    "\n",
    "        for tag in TAGS:\n",
    "            class_counts[tag] = 0\n",
    "\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for key, value in data.items():\n",
    "            if key in os.listdir(images_dir):\n",
    "                if is_valid_image_file(os.path.join(self.images_dir, key)):\n",
    "                    target = self.hot_encode_target(value)\n",
    "\n",
    "                    if len(target) == NUM_TAGS:\n",
    "                        image_label_dict[key] = target\n",
    "                        for v in value:\n",
    "                            class_counts[v] += 1\n",
    "\n",
    "                    else:\n",
    "                        print('Invalid file: ' + key + '. Skipping this file...')\n",
    "\n",
    "        self.items = list(image_label_dict.items())\n",
    "        print('Class counts: ', class_counts)\n",
    "\n",
    "        if (sum(class_counts.values()) > 23000):\n",
    "            phase = \"TRAIN\"\n",
    "        else:\n",
    "            phase = \"VAL\"\n",
    "        print(f\"{phase.upper()} SET STATISTICS:\")\n",
    "        total_images = sum(class_counts.values())\n",
    "        print(f\"Total images: {total_images}\")\n",
    "        for class_id, count in class_counts.items():\n",
    "            print(f\"Class {class_id}: {count} images\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.items[idx][0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.items[idx][1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = GPU_MODE\n",
    "use_mps = MPS_MODE\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(CUDA_DEVICE)\n",
    "\n",
    "if use_mps:\n",
    "   mps_device = torch.device(\"mps\")\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=100):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model = model\n",
    "    best_loss = torch.inf\n",
    "\n",
    "    losses = {'train': [], 'val': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('-' * 10)\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                optimizer = lr_scheduler(optimizer, epoch)\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            for data in dset_loaders[phase]:\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    try:\n",
    "                        inputs, labels = Variable(inputs.float().cuda()), Variable(labels.long().cuda())\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(\"ERROR! here are the inputs and labels before we print the full stack trace:\")\n",
    "                        print(inputs, labels)\n",
    "                        raise e\n",
    "                    \n",
    "                elif use_mps:\n",
    "                   try:\n",
    "                      inputs, labels = Variable(inputs.float().to(mps_device)), Variable(labels.long().to(mps_device))\n",
    "\n",
    "                   except Exception as e:\n",
    "                      print(\"ERROR! here are the inputs and labels before we print the full stack trace:\")\n",
    "                      print(inputs, labels)\n",
    "                      raise e\n",
    "                \n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if counter%100 == 0:\n",
    "                    print('Reached batch iteration', counter)\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                try:\n",
    "                    running_loss += loss.item()\n",
    "                except:\n",
    "                    print('unexpected error, could not calculate loss or do a sum.')\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes[phase]\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            losses[phase].append(epoch_loss)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    print('new best loss =', best_loss)\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "    print('returning and looping back')\n",
    "\n",
    "    return best_model, losses\n",
    "\n",
    "def exp_lr_scheduler(optimizer, epoch, init_lr=BASE_LR, lr_decay_epoch=EPOCH_DECAY):\n",
    "    \"\"\"Decay learning rate by a factor of DECAY_WEIGHT every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (DECAY_WEIGHT**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Epoch 0/4\n",
      "----------\n",
      "LR is set to 0.001\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.ComicDataset'>: it's not the same object as __main__.ComicDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 67\u001b[0m\n\u001b[1;32m     63\u001b[0m             label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(label)\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n\u001b[0;32m---> 67\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(split, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses by epoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, losses[split])\n",
      "Cell \u001b[0;32mIn[47], line 26\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, lr_scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdset_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hensight/hensight/lib/python3.11/site-packages/torch/utils/data/dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hensight/hensight/lib/python3.11/site-packages/torch/utils/data/dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/hensight/hensight/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/popen_spawn_posix.py:47\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, fp)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/multiprocessing/reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.ComicDataset'>: it's not the same object as __main__.ComicDataset"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    try:\n",
    "        multiprocessing.set_start_method('spawn')\n",
    "    except RuntimeError as e:\n",
    "        print(\"RuntimeError:\", e)\n",
    "\n",
    "    dsets = {}\n",
    "\n",
    "    dsets['train'] = ComicDataset(images_dir, TRAIN_JSON, data_transforms['train'])\n",
    "    dsets['val'] = ComicDataset(images_dir, VAL_JSON, data_transforms['val'])\n",
    "\n",
    "    dset_sizes = {split: len(dsets[split]) for split in ['train', 'val']}\n",
    "\n",
    "    print('Finished making datasets!')\n",
    "\n",
    "    dset_loaders = {}\n",
    "    for split in ['train', 'val']:\n",
    "        dset_loaders[split] = torch.utils.data.DataLoader(dsets[split], batch_size=BATCH_SIZE, shuffle=True, num_workers=12)\n",
    "\n",
    "    class ResNet50MultiLabel(nn.Module):\n",
    "        def __init__(self, num_classes):\n",
    "            super(ResNet50MultiLabel, self).__init__()\n",
    "            # Load a pre-trained ResNet-50 model\n",
    "            self.resnet50 = models.resnet50(pretrained=True)\n",
    "            \n",
    "            # Replace the final fully connected layer\n",
    "            # ResNet-50's fc layer output features is 2048\n",
    "            self.resnet50.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.resnet50(x)\n",
    "\n",
    "    model = ResNet50MultiLabel(NUM_TAGS)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    if use_gpu:\n",
    "        criterion.cuda()\n",
    "        model.cuda()\n",
    "\n",
    "    if use_mps:\n",
    "        criterion.to(mps_device)\n",
    "        model.to(mps_device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    model, losses = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        print(split, 'losses by epoch:', losses[split])\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(dsets['train']), size=(1,)).item()\n",
    "        img, label = dsets['train'][sample_idx]\n",
    "\n",
    "        # Convert the tensor image to numpy\n",
    "        img = img.numpy().transpose((1, 2, 0))  # Change from (C, H, W) to (H, W, C)\n",
    "        \n",
    "        # Undo the normalization\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = std * img + mean  # Apply the inverse of the initial normalization\n",
    "        img = np.clip(img, 0, 1)  # Ensure the values are between 0 and 1\n",
    "\n",
    "        # Plot the image\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(str(label))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img)  # img is now in the correct format for imshow\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('train_images.png')\n",
    "\n",
    "\n",
    "    def plot_training_history(losses):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for phase in ['train', 'val']:\n",
    "            plt.plot(losses[phase], label=f'{phase} loss')\n",
    "        plt.title('Loss over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        plt.savefig('loss_plot.png')\n",
    "\n",
    "    plot_training_history(losses)\n",
    "    torch.save(model.state_dict(), 'fine_tuned_best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
